% !TEX encoding = UTF-8 Unicode
% -*- coding: UTF-8; -*-
% vim: set fenc=utf-8

\chapter{Introdução}

Neste capítulo serão apresentadas a visão geral e a motivação dessa monografia, além da contribuição proposta.

\section{Visão geral e Contextualização}

% Simulações computacionais...análises...hipóteses científicas...
Simulações computacionais tornaram-se predominantes e omnipresentes no dia-a-dia de cientistas\footnote{Daqui em diante denominados \textit{usuários}.}, sendo necessárias na realização de análises que utilizam modelos computacionais complexos que lidam com grandes volumes de dados~\cite{silva2015analyzing}, permitindo a exploração de dados específicos de domínio para apoiar esses usuários na validação de hipóteses científicas ou comportamentos peculiares.

% Muitos programas...consumem e produzem muitos dados...
Essas simulações geralmente envolvem a execução de muitos programas do domínio científico, os quais intensivamente consomem e produzem muitos dados. A maior parte desses dados é armazenada em uma miscelânea de formatos de arquivo também no domínio da aplicação~\cite{silva2015analyzing}; por exemplo, \abbrev{FITS}{Flexible Image Transport System} FITS~\cite{greisen2002representations} em astronomia, ou \abbrev{HDF}{Hierarchical Data Format} HDF5~\cite{folk1999hdf5} e \abbrev{NetCDF}{Network Common Data Form} NetCDF~\cite{rew1990netcdf} em dinâmica de fluidos computacionais.
% Longo tempo para ser executada...mesmo em PAD...
Uma grande parte dessas simulações computacionais em larga escala leva um longo tempo para ser executada, mesmo em ambientes de \abbrev{PAD}{Processamento em Alto Desempenho} PAD (Processamento em Alto Desempenho)~\cite{silva2017raw}, onde o poder de computação é amplificado através da utilização de diversos núcleos computacionais.

% Rastrear grandezas...somente no fim...programas ad-hoc...SGBD...
Durante as mesmas, usuários comumente precisam rastrear grandezas de interesse, tais como resíduos, tempo de execução e estimativas de erro, baseadas em elementos de dados relacionados de vários arquivos, a fim de controlar a sua execução ao máximo possível~\cite{silva2016situ}.
Entretanto, esse rastreio costuma ser realizado somente ao fim da simulação, o que \textit{a priori} não é prático para o usuário, já que essas simulações levam um tempo considerável de execução mesmo em PAD, como mencionado anteriormente~\cite{silva2017raw}. Além disso, mesmo considerando que os arquivos produzidos sejam tipicamente apoiados por diversas linguagens de programação e bibliotecas, programas \textit{ad-hoc} precisam comumente ser desenvolvidos a fim de permitir análises em grande escala, as quais se tornam ainda mais custosas se realizadas com \abbrev{SGBD}{Sistema de Gerenciamento de Banco de Dados} SGBDs (Sistemas de Gerenciamento de Banco de Dados), pois eles aumentam a complexidade de execução em termos da estruturação e da carga dos dados ~\cite{silva2015analyzing}.

\section{Motivação}%
\label{sec:motivacao}

% SGWfCs...paralelização...proveniência...
Para amenizar o custo de tempo de execução, as simulações computacionais citadas anteriormente podem ser gerenciadas por um \abbrev{SGWfC}{Sistema de Gerência de \textit{Workflows} Científicos} SGWfC (Sistema de Gerência de \textit{Workflows} Científicos) paralelo, tal como o Kepler~\cite{ludascher2006scientific} e o Pegasus~\cite{deelman2005pegasus}, o que faz com que se beneficiem da proveniência e do paralelismo de dados entre os diferentes programas que compõem o seu \textit{workflow}\footnote{Em tradução livre, ``fluxo de trabalho''. No entanto, daqui em diante continuaremos a utilizar \textit{workflow}, por ser um termo mais preciso.}~\cite{bux2013parallelization}.
% Workflows...dataflows(dt, ds, phi)...DAG...
Tais \textit{workflows} científicos são composições de tarefas de processamento de dados sequenciais e concorrentes, cuja ordem de execução é determinada com base nas interdependências entre os dados~\cite{bux2013parallelization}. Eles podem ser modelados através de um fluxo de dados (\textit{dataflow}) que descreve todos os conjuntos de dados, atributos de dados, transformações de dados e dependências entre os mesmos~\cite{silva2017raw}. Esses fluxos de dados são usualmente especificados na forma de um \abbrev{DAG}{Directed Acyclic Graph --- Grafo Direcionado Acíclico} DAG (grafo direcionado acíclico), em que transformações de dados são representadas como nós, e conjuntos de dados são modelados como arestas direcionadas.

% Trade-offs entre usabilidade e poder de controle...
Os SGWfCs citados anteriormente são usualmente difíceis de serem configurados e utilizados pelos usuários; alguns deles tais como o Taverna~\cite{hull2006taverna} possuem uma boa ênfase em usabilidade, porém não compensam na paralelização e utilização de recursos computacionais distribuídos; perdendo, assim, sua efetividade.
% Dificuldade em não utilizar SGWfCs...
Eles facilitam o \textit{design}, a manutenção, a execução e o monitoramento de \textit{workflows} científicos. Entretanto, sem suporte ao rastreio de dados científicos, o desafio é analisar a propagação de dados de conjuntos de arquivos ao longo da execução da simulação, o que é bastante propenso a erros se realizado manualmente~\cite{silva2015analyzing}, pois são necessários: \( (i) \) a nomenclatura de arquivos de forma apropriada; \( (ii) \) escrever e gerenciar programas \textit{ad-hoc} para gerenciar cada transformação de dados e arquivos; e \( (iii) \) mapear o fluxo das transformações de dados, assim como dos elementos de dados consumidos e produzidos pela execução de cada transformação de dados.

No entanto, eis um dilema: existem três tipos básicos de consultas\footnote{Isso será mais aprofundado no~\autoref{chap:trabalhos-relacionados}.} que são rotineiramente utilizadas:

\begin{enumerate}
    \item conteúdo de arquivo específico de domínio;
    \item múltiplos arquivos relacionados através de transformações de dados / programas de simulação; e
    \item elementos de dados relacionados de múltiplos arquivos
\end{enumerate}

O dilema é que --- até onde se tem conhecimento durante a publicação deste documento --- todos os SGWfCs conhecidos realizam apenas consultas do tipo \( 1 \) ou \( 2 \), como o FastBit~\cite{wu2009fastbit} que realiza apenas consultas do tipo 1, e como o Chiron~\cite{ogasawara2013chiron} que é capaz de realizar ambos os tipos de consulta. Nenhum deles é capaz de realizar consultas do tipo 3.

\section{Contribuição}

Desse modo, como vimos na última seção, a capacidade de realizar todos os três tipos de consultas citados ainda é um problema em aberto, sendo especialmente importante em situações de larga escala, onde muitos dados são manipulados intensivamente.
Para preencher esse gargalo, foi proposta a arquitetura \abbrev{ARMFUL}{Analysis of Raw Data from Multiple Files} ARMFUL (Analysis of Raw Data from Multiple Files)\cite{silva2017raw,silva2016situ}: com ela, todos os três tipos de consultas podem ser realizados. Todos esses tipos de consultas podem ser apoiadas pela ARMFUL ao oferecer uma base de dados de proveniência, cujo objetivo é guardar as referências para os arquivos e os elementos de dados do domínio da aplicação selecionados pelos usuários, para que eles possam ser devidamente rastreados~\cite{silva2015analyzing}.

Dessa forma, os usuários podem submeter consultas para selecionar dados científicos de suas simulações científicas não apenas \textbf{após}, mas também \textbf{durante} a execução da simulação; o objetivo é a possibilidade de captação dos elementos de dados de interesse no momento em que eles são gerados~\cite{silva2015analyzing}. O benefício dessa abordagem é evitar que a extração (\textit{parsing}) dos dados tenha que ocorrer por completo; em vez disso, ela pode ser realizada dinamicamente (\textit{on-the-fly}), sem ter que fazer todo o carregamento dos dados em memória ou em um SGBD, o que evita a duplicação e a manutenção de dados no SGBD, e também reduz o custo computacional da consulta, que passa a ser realizada em menos tempo.

Mais especificamente, a contribuição desse trabalho é uma extensão da arquitetura ARMFUL apresentada em~\cite{silva2016situ,silva2017raw} com a introdução de um processador de consultas\footnote{Daqui em diante nomeado \textit{Query Processor} (QP).}.
O \abbrev{QP}{Query Processor --- Processador de Consultas} \textit{Query Processor} (QP) atua como um componente do ARMFUL que é responsável pela interação do usuário com os conjuntos de dados de suas simulações. A partir dele, o usuário é capaz de escrever uma consulta sem ter que aprender \abbrev{SQL}{Structured Query Language} SQL (\textit{Structured Query Language}), pois ela é representada em alto nível, em um formato que é posteriormente traduzido (convertido) para SQL de forma transparente para o usuário. O benefício imediato disso é diminuir a curva de aprendizado para que uma consulta possa ser realizada, pois o usuário precisa se preocupar \textit{a priori} apenas com o domínio da aplicação da simulação computacional e com os dados e grandezas de interesse que ele deseja consultar.

Outro benefício é o desempenho atingido com as consultas: o \textit{Query Processor} faz o pré-processamento da especificação da simulação computacional --- que só precisa ser realizado uma única vez, sempre que o QP é executado durante uma sessão --- em estruturas de dados eficientes em relação aos dados obtidos pelo componente de Captura de Dados de Proveniência (ou, do termo em inglês, \textit{Provenance Gatherer}) da arquitetura ARMFUL, de modo que consultas consecutivas beneficiam-se da proveniência já carregada na memória; reduzindo, portanto, o tempo de processamento da consulta.

\section{Estruturação do Texto}

A principal contribuição deste trabalho consiste no desenvolvimento do \textit{Query Processor}: como ele foi criado, como ele se integra à arquitetura ARMFUL previamente apresentada, e quais são os benefícios --- qualitativamente e quantitativamente --- que ele acrescenta à mesma.

Assim, ele está organizado da seguinte forma:
o \autoref{chap:referencial-teorico} apresenta o embasamento teórico, introduzindo e definindo os conceitos, definições e a terminologia que será utilizada ao longo do trabalho.
No \autoref{chap:trabalhos-relacionados} listamos algumas publicações relacionadas e recentes, algumas dentre as quais serviram como motivação e base para essa, e também abordamos a diferença entre os tipos de consulta mais comuns em simulações científicas.
O \autoref{chap:arquitetura-armful} aborda a arquitetura ARMFUL e apresenta o \textit{DfAnalyzer}, parte do qual a aplicação desenvolvida nesse trabalho é um componente.
No \autoref{chap:rastros-de-proveniencia} desenvolvemos a abordagem e mostramos os algoritmos utilizados para analisar rastros de proveniência dos arquivos e dados científicos de simulações computacionais.
No \autoref{chap:experimentos} são abordados os resultados obtidos através do \textit{Query Processor} e os experimentos realizados com o mesmo.
Finalmente, o \autoref{chap:conclusao} conclui o trabalho com perspectivas de trabalhos futuros.
