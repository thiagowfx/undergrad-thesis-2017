% !TEX encoding = UTF-8 Unicode
% -*- coding: UTF-8; -*-
% vim: set fenc=utf-8

\chapter{Introdução}

Neste capítulo são apresentadas a visão geral e a motivação desta monografia, além da contribuição proposta.

\section{Visão geral e Contextualização}

% Simulações computacionais...análises...hipóteses científicas...
Simulações computacionais tornaram-se predominantes e omnipresentes no dia-a-dia de cientistas\footnote{Daqui em diante denominados \textit{usuários}.}, sendo necessárias na realização de análises que utilizam modelos computacionais complexos que lidam com grandes volumes de dados~\cite{silva2015analyzing}. Isso permite a exploração de dados específicos de domínio para apoiar esses usuários na validação de hipóteses científicas ou comportamentos peculiares.

% Muitos programas...consumem e produzem muitos dados...
Essas simulações geralmente envolvem a execução de muitos programas do domínio científico, os quais intensivamente consomem e produzem muitos dados. A maior parte desses dados é armazenada em diversos formatos de arquivo também no domínio da aplicação~\cite{silva2015analyzing}, por exemplo, \abbrev{FITS}{Flexible Image Transport System} FITS~\cite{greisen2002representations} em astronomia, ou \abbrev{HDF}{Hierarchical Data Format} HDF5~\cite{folk1999hdf5} e \abbrev{NetCDF}{Network Common Data Form} NetCDF~\cite{rew1990netcdf} em dinâmica de fluidos computacionais.
% Longo tempo para ser executada...mesmo em PAD...
Uma grande parte dessas simulações computacionais em larga escala leva um longo tempo para ser executada, mesmo em ambientes de \abbrev{PAD}{Processamento em Alto Desempenho} PAD (Processamento em Alto Desempenho)~\cite{silva2017raw}, onde o poder de computação é amplificado através da utilização de diversos núcleos computacionais.

% Rastrear grandezas...somente no fim...programas ad-hoc...SGBD...
Durante as simulações, usuários com frequência precisam rastrear grandezas de interesse, tais como resíduos, tempo de execução e estimativas de erro, baseadas em elementos de dados relacionados de vários arquivos, a fim de controlar a sua execução ao máximo possível~\cite{silva2016situ}. Contudo, esse rastreamento costuma ser realizado manualmente durante a execução dessas simulações. Nesse caso, a alternativa torna-se realizar esse rastreamento somente ao fim das simulações, o que não é prático para o usuário, já que essas simulações levam um tempo considerável de execução mesmo em PAD~\cite{silva2017raw}. Além disso, mesmo considerando que os arquivos produzidos sejam tipicamente apoiados por diversas linguagens de programação e bibliotecas, diversos programas \textit{ad-hoc} precisam ser desenvolvidos a fim de permitir análises em grande escala.

% MARTA: remover essa parte:
% , as quais se tornam ainda mais custosas se realizadas com \abbrev{SGBD}{Sistema de Gerenciamento de Banco de Dados} SGBDs (Sistemas de Gerenciamento de Banco de Dados), pois eles aumentam a complexidade de execução em termos da estruturação e da carga dos dados ~\cite{silva2015analyzing}.

\section{Motivação}%
\label{sec:motivacao}

% SGWfCs...paralelização...proveniência...
As simulações computacionais podem ser gerenciadas por um \abbrev{SGWfC}{Sistema de Gerência de \textit{Workflows} Científicos} SGWfC (Sistema de Gerência de \textit{Workflows} Científicos) paralelo, tal como o Kepler~\cite{ludascher2006scientific} e o Pegasus~\cite{deelman2005pegasus}, o que faz com que se beneficiem da proveniência e do paralelismo de dados entre os diferentes programas que compõem o seu \textit{workflow}\footnote{Em tradução livre, ``fluxo de trabalho''. No entanto, daqui em diante continuaremos a utilizar \textit{workflow}, por ser um termo mais preciso.}~\cite{bux2013parallelization}.
% Workflows...dataflows(dt, ds, phi)...DAG...
Tais \textit{workflows} científicos são composições de tarefas de processamento de dados sequenciais e concorrentes, cuja ordem de execução é determinada com base nas interdependências entre os dados~\cite{bux2013parallelization}. Eles podem ser modelados através de um fluxo de dados (\textit{dataflow}) que descreve todos os conjuntos de dados, atributos de dados, transformações de dados e dependências entre os mesmos~\cite{silva2017raw}. Esses fluxos de dados são usualmente especificados na forma de um \abbrev{DAG}{Directed Acyclic Graph --- Grafo Direcionado Acíclico} DAG (grafo direcionado acíclico), em que transformações de dados são representadas como nós, e conjuntos de dados são modelados como arestas direcionadas.

% Trade-offs entre usabilidade e poder de controle...
Os SGWfCs são usualmente difíceis de serem configurados e utilizados pelos usuários -- alguns deles, tais como o Taverna~\cite{hull2006taverna}, possuem uma boa ênfase em usabilidade, porém não compensam na paralelização e utilização de recursos computacionais distribuídos, perdendo, assim, sua efetividade.
% Dificuldade em não utilizar SGWfCs...
Eles facilitam o \textit{design}, a manutenção, a execução e o monitoramento de \textit{workflows} científicos. Entretanto, sem suporte ao rastreamento de dados científicos, o desafio é analisar a propagação de dados de conjuntos de arquivos ao longo da execução da simulação, o que é bastante propenso a erros se realizado manualmente~\cite{silva2015analyzing}. Isso porque são necessários: \( (i) \) a nomenclatura de arquivos de forma apropriada; \( (ii) \) escrever e gerenciar programas \textit{ad-hoc} para gerenciar cada transformação de dados e arquivos; e \( (iii) \) mapear o fluxo das transformações de dados, assim como dos elementos de dados consumidos e produzidos pela execução de cada transformação de dados.

% Marta(antes): Existem três tipos básicos de consultas\footnote{Isso será mais aprofundado no~\autoref{chap:analise-solucoes-consultas-dados-cientificos}.} que são rotineiramente utilizadas em simulações científicas:

Silva et al.~\cite{silva2015analyzing} consideram que existem três tipos básicos de consulta\footnote{Isso será mais aprofundado no~\autoref{chap:analise-solucoes-consultas-dados-cientificos}.} que são rotineiramente utilizadas em simulações científicas:

\begin{enumerate}
    \item conteúdo de arquivo específico de domínio;
    \item múltiplos arquivos relacionados através de transformações de dados / programas de simulação; e
    \item elementos de dados relacionados de múltiplos arquivos
\end{enumerate}

% Por exemplo, o FastBit~\cite{wu2009fastbit} é capaz de realizar apenas consultas do tipo 1, o Chiron~\cite{ogasawara2013chiron} é capaz de realizar consultas dos tipos 1 e 2, enquanto o NoWorkflow~\cite{murta2014noworkflow} e o Tigres~\cite{hendrix2016tigres} são capazes de realizar consultas dos tipos 2 e 3. Contudo, os dois últimos não são focados em dados científicos presentes em arquivos.

\section{Contribuição}

% Desse modo, como vimos na última seção, a capacidade de realizar todos os três tipos de consultas citados ainda é um problema em aberto, sendo especialmente importante em situações de larga escala, onde muitos dados são manipulados intensivamente.
Silva et al.~\cite{silva2015analyzing} observam que a capacidade de realizar todos os três tipos de consultas citados ainda é um problema em aberto, sendo especialmente importante em situações de larga escala, onde muitos dados são manipulados intensivamente.
Para preencher esse gargalo, Silva et al.~\cite{silva2015analyzing} propuseram a arquitetura \abbrev{ARMFUL}{Analysis of Raw Data from Multiple Files} ARMFUL (Analysis of Raw Data from Multiple Files)~\cite{silva2017raw,silva2016situ}: com ela, todos os três tipos de consultas podem ser realizados. Todos esses tipos de consultas podem ser apoiadas pela ARMFUL ao oferecer uma base de dados de proveniência, cujo objetivo é guardar as referências para os arquivos e os elementos de dados do domínio da aplicação selecionados pelos usuários, para que eles possam ser devidamente rastreados~\cite{silva2015analyzing}.

Dessa forma, os usuários podem submeter consultas para selecionar dados científicos de suas simulações não apenas após, mas também durante a execução da simulação: o objetivo é a possibilidade de captação dos elementos de dados de interesse no momento em que eles são gerados~\cite{silva2015analyzing}. O benefício dessa abordagem é evitar que a extração (\textit{parsing}) dos dados tenha que ocorrer por completo, em vez disso, ela pode ser realizada dinamicamente (\textit{on-the-fly}), sem ter que fazer todo o carregamento dos dados em memória ou em um SGBD (Sistema de Gerenciamento de Banco de Dados) \abbrev{SGBD}{Sistema de Gerenciamento de Banco de Dados}, o que evita a duplicação e a manutenção de dados no SGBD, e também reduz o custo computacional da consulta, que passa a ser realizada em menos tempo.

% MARTA: essa é a definição do meu problema.
Apesar da arquitetura ARMFUL ser bem abrangente e eficiente em prover consultas envolvendo dados de domínio, de proveniência e de execução, ela oferece um recurso limitado para o usuário submeter consultas dessas três classes. Na verdade, o usuário precisa não apenas conhecer bem a linguagem SQL, mas também os relacionamentos necessários para permitir o rastreamento entre múltiplos arquivos de dados.
Este trabalho tem por objetivo facilitar essa interação do usuário com a elaboração de consultas analíticas ao utilizar a ARMFUL.

Mais especificamente, a contribuição deste trabalho é uma extensão da arquitetura ARMFUL apresentada em~\cite{silva2016situ,silva2017raw} com a introdução de um processador de consultas, denominado QPP (\textit{Query Preprocessor}) \abbrev{QPP}{Query Preprocessor --- Pré-Processador de Consultas}. O QPP atua como um componente do ARMFUL que é responsável pela interação do usuário com os conjuntos de dados de suas simulações. A partir dele, o usuário é capaz de escrever uma consulta sem ter que aprender \abbrev{SQL}{Structured Query Language} SQL (\textit{Structured Query Language}), pois ela é representada em alto nível, em um formato que é posteriormente traduzido (convertido) para SQL de forma transparente para o usuário. Isso pode facilitar o uso do sistema, já que o usuário não precisaria ter profundos conhecimentos em SQL e poderia se preocupar apenas com o domínio da aplicação da simulação computacional e com os dados e grandezas de interesse para as consultas.
% REMOVER(Renan): O benefício imediato disso é diminuir a curva de aprendizado para que uma consulta possa ser realizada, pois o usuário precisa se preocupar \textit{a priori} apenas com o domínio da aplicação da simulação computacional e com os dados e grandezas de interesse que ele deseja consultar.

Outro benefício é o desempenho atingido com as consultas: o QPP faz o pré-processamento da especificação da simulação computacional --- que só precisa ser realizado uma única vez, sempre que o QPP é executado durante uma sessão --- em estruturas de dados eficientes em relação aos dados obtidos pelo componente de Captura de Dados de Proveniência (ou, do termo em inglês, \textit{Provenance Gatherer}) da arquitetura ARMFUL. Desse modo, consultas consecutivas beneficiam-se da proveniência já carregada na memória; reduzindo, portanto, o tempo de processamento.

\section{Estruturação do Texto}

A principal contribuição deste trabalho consiste no desenvolvimento do QPP: como ele foi criado, como ele se integra à arquitetura ARMFUL previamente apresentada, e quais são os benefícios --- qualitativamente e quantitativamente --- que ele acrescenta à mesma.

Assim, ele está organizado da seguinte forma:
o \autoref{chap:referencial-teorico} apresenta o embasamento teórico, introduzindo e definindo os conceitos, definições e a terminologia que será utilizada ao longo do trabalho.
No \autoref{chap:analise-solucoes-consultas-dados-cientificos} listamos algumas publicações relacionadas e recentes, algumas dentre as quais serviram como motivação e base para essa, e também abordamos a diferença entre os tipos de consulta mais comuns em simulações científicas.
O \autoref{chap:arquitetura-armful} aborda a arquitetura ARMFUL e apresenta o \textit{DfAnalyzer}.
No \autoref{chap:rastros-de-proveniencia} desenvolvemos a abordagem e mostramos os algoritmos utilizados para analisar rastros de proveniência dos arquivos e dados científicos de simulações computacionais.
No \autoref{chap:experimentos} são abordados os resultados obtidos através do QPP e os experimentos realizados com o mesmo.
Finalmente, o \autoref{chap:conclusao} conclui o trabalho com perspectivas de trabalhos futuros.
