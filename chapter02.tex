% !TEX encoding = UTF-8 Unicode
% -*- coding: UTF-8; -*-
% vim: set fenc=utf-8

\chapter{Referencial Teórico}%
\label{chap:referencial-teorico}

Nesse capítulo serão abordados alguns conceitos e a terminologia que será utilizada ao longo desta monografia. Parte desse conteúdo, que será referenciado por~\cite{silva2015propostadoutorado}, é baseada na proposta de doutorado do M. Sc. Vítor Silva Sousa, co-orientador deste trabalho.

\section{Simulação Computacional}

Uma \textbf{simulação computacional}, também chamada de \textbf{simulação científica}, é um ``método de abstração e sistematização do processo experimental ou parte dele''~\cite{silva2015propostadoutorado,dias2015data}. Ela emergiu como um meio de executar experimentos científicos em ambientes computacionais~\cite{ogasawara2011algebraic}, e consiste de um ou vários programas de simulação específicos. Tais programas de simulação, em particular, são encadeados para realizar o processamento de dados necessários na condução do experimento científico de interesse.

Dessa forma, uma simulação computacional pode ser representada por meio de um fluxo de dados (elucidado na \autoref{sec:dataflow}), no qual ``os programas de simulação correspondem às transformações de dados e as dependências de dados correspondem ao fluxo de dados entre duas transformações de dados''~\cite{silva2015propostadoutorado,ogasawara2011algebraic}. Uma \textbf{transformação de dados} é definida como um componente da simulação computacional que é capaz de executar programas, com parâmetros de entrada e de saída, os quais são utilizados para representar dependências entre cada uma das transformações de dados. Os dados consumidos ou produzidos pelos programas de simulação são representados por \textbf{conjuntos de dados} de entrada ou de saída, respectivamente. Cada conjunto de dados assume um conjunto pré-definido de \textbf{atributos de dados}, enquanto cada elemento de dados desse conjunto apresenta valores para cada atributo de dados pré-definido.

\section{Fluxo de dados}%
\label{sec:dataflow}

% NOTA: fluxo de dados é o schema inteiro (e não apenas um único caminho no DAG)
% NOTA: coleção de dados pode ser vista como uma definição virtual

\subsection{Conceito}

Um \textbf{fluxo de dados} (do inglês \textit{dataflow}) é modelado como um grafo direcionado acíclico (DAG), no qual os vértices (nós) representam as transformações de dados\footnote{Isto é, quaisquer \emph{programas} de uma simulação computacional.} de uma simulação computacional, e as arestas direcionadas representam o conjuntos de dados entre as transformações~\cite{silva2017raw}.

Formalmente, uma especificação de fluxo de dados \( D \) é definida como \[ D = (S, T, \Phi) \] onde:
\begin{itemize}
    \item \( S = \{ds_1, ds_2, \ldots, ds_{\alpha}\} \) é um conjunto de conjuntos de dados
    \item \( T = \{dt_1, dt_2, \ldots, dt_{\beta}\} \) é um conjunto de transformações
    \item \( \Phi = \{\phi_1, \phi_2, \ldots, \phi_{\gamma}\} \) é um conjunto de dependência de dados
\end{itemize}

\subsection{Conjunto de dados}

A especificação de um \textbf{conjunto de dados} \( ds \) é dada por \[ ds = (A, C) \] onde:
\begin{itemize}
    \item \( A = \{da_1, da_2, \ldots, da_{\delta} \} \) é um conjunto de atributos de dados
    \item \( C = \{dc_1, dc_2, \ldots, dc_{\zeta} \} \) é um conjunto de coleções de dados
\end{itemize}

Em simulações computacionais, conjuntos de dados correspondem a dados científicos.

\subsection{Transformação de dados}

Uma \textbf{transformação de dados} \( dt \) é caracterizada pelo consumo de um ou mais conjuntos de dados de entrada e pela produção de um ou mais conjuntos de dados de saída. O exemplo da \autoref{fig:example-transformation} ilustra essa definição.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.35\textwidth]{img/example-data-transformation}
    \caption[Exemplo de transformação de dados]{Exemplo de transformação de dados, \( dt \), com dois conjuntos de dados de entrada, \( ds_1 \) e \( ds_2 \), e dois conjuntos de dados de saída, \( ds_3 \) e \( ds_4 \).}%
    \label{fig:example-transformation}
\end{figure}

No contexto de simulações computacionais, transformações de dados correspondem a programas científicos.

\subsection{Dependência de dados}

Uma especificação de \textbf{dependência de dados} \( \phi \) é definida como \[ \phi = (ds, dt_{\textrm{previous}}, dt_{\textrm{next}}) \] onde:
\begin{itemize}
    \item \( ds \) é um conjunto de dados
    \item \( dt_{\textup{previous}} \) é uma transformação de dados que {\bf produz} coleções de dados para o conjunto de dados \( ds \)
    \item \( dt_{\textup{next}} \) é uma transformação de dados que {\bf consome} coleções de dados do conjunto de dados \( ds \)
\end{itemize}

\subsection{Atributo de dados}

Um \textbf{atributo de dados} é especificado da seguinte forma: \[ da = (\textrm{nome},\textrm{tipo}) \therefore \textrm{tipo} \in \{\textup{inteiro}, \textup{ponto flutuante}, \textup{texto}, \textup{arquivo}, \textup{booleano}\} \]

O nome do atributo de dados é um identificador que deve ser único em um mesmo conjunto de dados. O tipo do atributo provê um significado semântico ao mesmo. O exemplo da \autoref{tab:dataset-attributes-example} ilustra essa definição.

\begin{table}[ht]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Nome do atributo} & \textbf{Tipo do atributo} \\
        \hline
        Nome             & texto           \\
        \hline
        Idade            & inteiro         \\
        \hline
        Altura \( (m) \) & ponto flutuante \\
        \hline
    \end{tabular}
    \caption[Exemplo de conjunto de dados com seus respectivos atributos de dados]{Exemplo de conjunto de dados de usuários com seus respectivos atributos de dados.}%
    \label{tab:dataset-attributes-example}
\end{table}

\subsection{Coleção de dados}

Uma \textbf{coleção de dados}, também chamada de conjunto de elementos de dados, é definida como \[ dc = \{ de_1, de_2, \ldots, de_{\eta} \} \] onde cada \( de \) é um elemento de dados.

\subsection{Elemento de dados}

Um \textbf{elemento de dados} é definido como

\[ de = \{ v_1, v_2, \ldots, v_{\theta} \} \therefore \#(ds.A) = \#(de) \]

onde o i-ésimo \( v \) é o valor do i-ésimo atributo de dados \( da \) de um conjunto de dados \( ds \). \( \#(S) \) representa a cardinalidade do conjunto \( S \), i.e., a quantidade de elementos presentes no mesmo. Note que a quantidade de atributos do conjunto de dados \( ds \) deve ser igual à quantidade de valores presentes no elemento de dados \( de \).

Para exemplificar a relação entre coleção de dados e elemento de dados, considere a \autoref{tab:data-collections-and-data-elements}.

\begin{table}[ht]
    \centering
    \begin{tabular}{c|c|c|cc}
        & \textbf{Nome} & \textbf{Idade} & \textbf{Altura \((m)\)} \\
        \( de_{1} \) & Alice   & 22 & \( 1,77 \) & \rdelim\}{2}{.1mm}[\( dc_{1} \)] \\
        \( de_{2} \) & Bob     & 25 & \( 1,79 \) \\
        \( de_{3} \) & Charlie & 42 & \( 1,85 \) & \rdelim\}{1}{.1mm}[\( dc_{2} \)] \\
    \end{tabular}
    \caption[Relação entre coleção de dados e elemento de dados]{Relação entre coleção de dados e elemento de dados. Estes elementos de dados são instâncias do conjunto de dados de usuários da \autoref{tab:dataset-attributes-example}. Cada linha numerada da tabela é um elemento de dados; e existem duas coleções de dados: \( dc_{1} = \{de_{1}, de_{2}\} \) e \( dc_{2} = \{ de_{3} \} \).}%
    \label{tab:data-collections-and-data-elements}
\end{table}

\subsection{Um exemplo}%
\label{sec:um-exemplo-de-dataflow}

Para ilustrar as definições e especificações da \autoref{sec:dataflow}, vamos utilizar uma pequena amostra de um fluxo de dados real, de um conjunto de dados de um experimento de sedimentação de fluidos. Na \autoref{fig:example-dataflow-specification} podemos ver o DAG correspondente a esse fluxo de dados \( D \): ele contém duas transformações de dados, \textsc{inputmesh} e \textsc{createequationsystems}, e três conjuntos de dados, \textsc{iinputmesh}, \textsc{oinputmesh} e \textsc{ocreateequationsystems}, assim como três dependências de dados. Eis a especificação de \( D \):

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.35\textwidth]{img/example-dataflow-specification}
    \caption[Exemplo de especificação de fluxo de dados]{Exemplo de especificação de fluxo de dados, com duas transformações de dados e três conjuntos de dados.}%
    \label{fig:example-dataflow-specification}
\end{figure}

\[
    \begin{array}{rl}
    % \begin{cases}
        D = & (S, T, \Phi) \\
        S = & \{ \textsc{iinputmesh}, \textsc{oinputmesh}, \textsc{ocreateequationsystems} \} \\
        T = & \{ \textsc{inputmesh}, \textsc{outputmesh} \} \\
        \multirow{3}{*}{\Phi{} =}
            & \{ (\varnothing, \textsc{iinputmesh}, \textsc{inputmesh}), \\
            & (\textsc{inputmesh}, \textsc{oinputmesh}, \textsc{createequationsystems}), \\
            & (\textsc{createequationsystems}, \textsc{ocreateequationsystems}, \varnothing) \}
    \end{array}
    % \end{cases}
\]

\textbf{Observação:} o símbolo \( \varnothing \) denota \emph{nulo}, indicando que uma das transformações de dados correspondente à dependência de dados não existe.

Além disso, podemos ver alguns dos atributos de dados do conjunto de dados \textsc{iinputmesh} na \autoref{tab:iinputmesh-attributes}, assim como alguns de seus valores na \autoref{tab:iinputmesh-values}. Cada uma das linhas da \autoref{tab:iinputmesh-values} corresponde a um elemento de dados diferente, e todo o conjunto desses elementos de dados compõe toda a coleção de dados do conjunto de dados.

\begin{table}[ht]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Nome do atributo} & \textbf{Tipo do atributo} \\
        \hline
        id & inteiro \\
        mesh{\_}file & arquivo \\
        dim & inteiro \\
        simulationid & inteiro \\
        restart{\_}control & booleano \\
        \hline
    \end{tabular}
    \caption[Atributos de dados do conjunto de dados \textsc{iinputmesh}]{Alguns dos atributos de dados do conjunto de dados \textsc{iinputmesh}.}%
    \label{tab:iinputmesh-attributes}
\end{table}

\begin{table}[ht]
    \centering
    \begin{tabular}{c|c|c|c|c}
        \textbf{id} & \textbf{mesh{\_}file} & \textbf{dim} & \textbf{simulationid} & \textbf{restart{\_}control} \\
        \hline
        1 & \texttt{/sedimentation/necker3d.msh} & 3 & 1 & \textrm{falso} \\
        2 & \texttt{/sedimentation/necker3d-2.msh} & 3 & 2 & \textrm{verdadeiro} \\
    \end{tabular}
    \caption[Valores dos atributos de dados de \textsc{iinputmesh}]{Alguns dos valores dos atributos de dados de \textsc{iinputmesh}.}%
    \label{tab:iinputmesh-values}
\end{table}

\section{Proveniência de dados}

\subsection{Definição}

% upstream: http://www.aulete.com.br/proveni%C3%AAncia
O dicionário Aulete Digital~\cite{auletedigitalonline} define \textbf{proveniência} como
``lugar de onde alguém ou alguma coisa provém; origem; FONTE;''. Em simulações computacionais, a proveniência nos ajuda a interpretar e entender resultados. Através da examinação e da cadeia de passos que criaram um certo resultado, nós podemos verificar que o experimento foi: (i) realizado de acordo com os procedimentos aceitáveis; (ii) inspecionar as suas entradas; e, em alguns casos, (iii) reproduzir os mesmos resultados~\cite{freire2008provenance}.

Questões básicas sobre dados científicos podem ser respondidas através do conhecimento e da introspecção de sua proveniência, tais como

\begin{enumerate}
    \item quem criou o dado, e quando foi essa criação?
    \item quem modificou o dado, e quando essa modificação ocorreu?
    \item que processo criou o dado?
    \item que outros dados foram produzidos a partir dos dados originais?
\end{enumerate}

Um dos componentes mais importantes que podemos obter com proveniência são suas informações sobre \textbf{causalidade}, isto é, a relação de dados de entrada que, associados a um processo, levam a um determinado conjunto de dados de saída~\cite{freire2008provenance}. A causalidade pode ser representada através de fluxos de dados e de grafos --- onde os nós correspondem a processos e arestas correspondem a dados científicos ---, como no exemplo da \autoref{sec:um-exemplo-de-dataflow}.

Um segundo exemplo relevante de componente de proveniência são as informações definidas e providas pelo usuário, as quais não podem ser capturadas automaticamente~\cite{freire2008provenance}. Esse tipo de informação é usualmente provido em níveis de granularidade arbitrários através de anotações e observações do usuário.

\subsection{Categorias de dados de proveniência}

Existem dois tipos de proveniência envolvidos na gerência de fluxo de dados: \textbf{prospectiva} e \textbf{retrospectiva}~\cite{murta2014noworkflow,freire2008provenance}:

\begin{itemize}
% murta2014noworkflow ++ freire2008provenance
    \item A \textbf{proveniência prospectiva} captura a especificação e a estrutura de uma tarefa computacional --- por exemplo, um \textit{script}, ou um programa de simulação --- e associa a ela os passos que precisam ser seguidos para gerar um conjunto de dados. Ela corresponde à definição de um fluxo de dados e ao seu grafo, transformações de dados e dados científicos relacionados.
% murta2014noworkflow ++ freire2008provenance
    \item Por outro lado, a \textbf{proveniência retrospectiva} captura não apenas os passos executados de uma tarefa computacional, mas também informações relacionadas ao ambiente e tempo de execução da mesma - por exemplo, quais parâmetros foram passados aos programas, qual \abbrev{PID}{Process ID} processo (PID) do sistema operacional foi executado, por quem o PID foi executado, qual foi a duração total (incluindo seu instante de início e de fim) do mesmo, ou quais variáveis de ambiente do sistema operacional estavam definidas. Sua estrutura do grafos é similar à da proveniência prospectiva.
\end{itemize}

Através dos dois tipos citados de proveniência, um sistema de fluxo de dados é capaz de orquestrar e prover diferentes níveis de abstração para a execução de uma simulação científica~\cite{murta2014noworkflow}, os quais são inexistentes em programas de simulação, tais como \textit{scripts}. Como iniciativas para a gerência de dados de proveniência, pode-se citar o NoWorkflow~\cite{murta2014noworkflow}, o YesWorkflow~\cite{mcphillips2015yesworkflow}, o DfAnalyzer~\cite{silva2016situ} e a biblioteca Tigres~\cite{hendrix2016tigres}.

Ademais, a captura de proveniência de dados pode ser realizada de duas formas distintas, \textit{offline} e \textit{online}~\cite{silva2015propostadoutorado}. A captura \textit{offline} consiste em armazenar os dados de uma simulação computacional em um determinado repositório logo \textbf{após} a execução da mesma --- por exemplo, como realizado pelo Kepler~\cite{ludascher2006scientific}. Em contrapartida, a captura \textit{online} consiste na obtenção e no armazenamento de dados \textbf{em tempo de execução}, como realizado no Pegasus~\cite{deelman2005pegasus} e no Swift/T~\cite{zhao2007swift}.

Uma simples observação é que o desempenho da captura de proveniência \textit{online} tende a ser ligeiramente pior do que a \textit{offline}, devido à possível sobrecarga do armazenamento de dados de proveniência concorrentemente ao processamento dos programas de simulação. Em outra perspectiva, vale enfatizar que a captura \textit{online} é mais flexível e tem um potencial analítico maior, pois permite que os usuários realizem consultas mesmo antes do término da simulação, o que possui um valor inestimável, uma vez que simulações computacionais são comumente realizadas em larga escala sendo, portanto, custosas e demoradas.

\subsubsection{Um exemplo}

Para ilustrar a diferença entre os dois tipos de proveniência apresentados, considere o clássico exemplo de contagem de palavras\footnote{Cujo objetivo é obter a ordem decrescente de frequência das palavras que aparecem no texto.} (\textit{word counting}), no qual o conjunto de dados inicial é um arquivo de texto em \abbrev{ASCII}{American Standard Code for Information Interchange} ASCII. A primeira tarefa de processamento é a leitura e subsequente análise do arquivo de texto a fim de extrair palavras do mesmo. A segunda etapa é realizar a contagem das palavras a partir da lista de palavras obtida no passo anterior. Finalmente, o último passo de processamento é ordenar em ordem descrescente a frequência de palavras obtida no passo anterior.

A proveniência prospectiva desse experimento poderia ser representada através do grafo da \autoref{fig:word-count-prospective}. Por outro lado, a proveniência retrospectiva do último passo (ordenação) poderia ter capturado em tempo de execução algumas das informações presentes na \autoref{tab:word-count-retrospective}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{img/word-count-prospective}
    \caption[Proveniência prospectiva do exemplo de contagem de palavras]{Proveniência prospectiva do exemplo de contagem de palavras.}%
    \label{fig:word-count-prospective}
\end{figure}

\begin{table}[ht]
    \centering
    \begin{tabular}{r|l}
        \hline
        \textit{Timestamp} de início & 2017-06-25 03:11:05.231                         \\
        \textit{Timestamp} de fim    & 2017-06-25 03:11:09.586                         \\
        PID                          & 4671                                            \\
        Linha de comando             & \texttt{./sort --order=desc --in=freq-list.csv} \\
        Variáveis de ambiente        & \texttt{PWD=/home/tperrotta;PATH=/usr/bin:/bin} \\
        Usuário                      & tperrotta                                       \\
        \hline
    \end{tabular}
    \caption[Proveniência retrospectiva do exemplo de contagem de palavras]{Proveniência retrospectiva do exemplo de contagem de palavras da etapa de ordenação decrescente.}%
    \label{tab:word-count-retrospective}
\end{table}

\section{Rastreamento de dados de proveniência}

\subsection{Mapeamento de atributos de dados}

\perrotta{TODO}

\subsection{Gerência do fluxo de dados no nível físico}

O \textbf{rastreamento físico} de dados de proveniência gerencia a proveniência de \emph{elementos de dados} individuais, isto é, num nível de granularidade fino. Nessa abordagem é necessário etiquetar cada elemento de dado com identificadores, de forma a habilitar a gerência do fluxo de dados. Esse tipo de proveniência captura muitos detalhes, os quais podem ser úteis na depuração de simulações devido à sua gerência em um nível de granularidade fina dos elementos de dados~\cite{silva2017raw}.

\subsection{Gerência do fluxo de dados no nível lógico}

\perrotta{REESCREVER}

O \textbf{rastreamento lógico} de dados de proveniência, de forma análoga ao rastreamento físico, também rastreia o fluxo de elementos de dados, só que a investigação do rastro é realizada em relação ao \emph{conjunto de dados}, em vez de elementos de dados. Dessa maneira, menos dados de proveniência precisam ser armazenados, já que um fluxo de dados costuma ter bem menos transformações do que elementos de dados. Além disso, o rastreamento lógico pode ser \emph{automaticamente} derivado das especificações das transformações de dados, uma vez que elas já apresentam propriedades sobre conjuntos de dados consumidos e produzidos~\cite{ikeda2013logical,silva2017raw}.

\subsubsection{Exemplo}

\perrotta{Exemplo para ilustrar: diferença entre físico e lógico}
\missingfigure{Exemplo para ilustrar: diferença entre físico e lógico}

% 

% REVIEW: devo falar de mapeamento de atributos no contexto de proveniência lógica aqui??
% REVIEW: Mecanismos para processamento de consultas ??